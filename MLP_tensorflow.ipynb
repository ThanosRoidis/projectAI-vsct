{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensoflow MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 cost= 129.319543434\n",
      "Epoch: 0002 cost= 33.827537767\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9008\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A Multilayer Perceptron implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 2\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(batch_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    " \n",
    "import vist\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sis's [val] loaded. It took 0.24 seconds.\n",
      "Make mapping ...\n",
      "Mapping for [Albums][Images][Stories][Sents] done.\n",
      "Topics (#albums) (#stories)\n",
      "0.4th_of_july (44)(220)\n",
      "1.MISC (60)(300)\n",
      "2.amusement_park (103)(515)\n",
      "3.award_ceremony (16)(80)\n",
      "4.baby_shower (5)(25)\n",
      "5.bar_mitzvah (8)(40)\n",
      "6.bat_mitzvah (2)(10)\n",
      "7.beach (150)(750)\n",
      "8.bike_race (29)(145)\n",
      "9.birthday (87)(435)\n",
      "10.birthday_party (20)(100)\n",
      "11.breaking_up (77)(385)\n",
      "12.building_a_house (98)(490)\n",
      "13.camping (1)(5)\n",
      "14.car_accident (26)(130)\n",
      "15.carnival (57)(285)\n",
      "16.christmas (20)(100)\n",
      "17.church (47)(235)\n",
      "18.cinco_de_mayo (20)(100)\n",
      "19.cooking_dinner (19)(95)\n",
      "20.day_parade (23)(115)\n",
      "21.easter (50)(250)\n",
      "22.eid_al-adha (2)(10)\n",
      "23.eid_al-fitr (3)(15)\n",
      "24.engagement (17)(85)\n",
      "25.fair (14)(70)\n"
     ]
    }
   ],
   "source": [
    "with open(\"img2features\", 'rb') as file:\n",
    "        img2features = pickle.load(file)\n",
    "        \n",
    "vist_images_dir = 'data/val.images'\n",
    "vist_annotations_dir = 'data'\n",
    "sis = vist.Story_in_Sequence(vist_images_dir, vist_annotations_dir, ['val'])\n",
    "\n",
    "\n",
    "topic2albums = {} \n",
    "\n",
    "for album in sis.Albums.values():\n",
    "    album_id = album['id']\n",
    "    vist_label = album[\"vist_label\"]\n",
    "    \n",
    "    if not vist_label in topic2albums: \n",
    "        topic2albums[vist_label] = [album_id]\n",
    "    else: \n",
    "        topic2albums[vist_label].append(album_id)\n",
    "        \n",
    "        \n",
    "topic2stories = {}\n",
    "\n",
    "for topic in topic2albums:\n",
    "    topic2stories[topic] = []\n",
    "    \n",
    "    topic_albums = topic2albums[topic];\n",
    "    for album_id in topic_albums:\n",
    "        stories = sis.Albums[album_id]['story_ids']\n",
    "        topic2stories[topic].extend(stories)\n",
    "        \n",
    "    \n",
    "\n",
    "print(\"Topics (#albums) (#stories)\")\n",
    "for i,key in enumerate(sorted(topic2albums.keys())):         \n",
    "    print(\"%d.%s (%d)(%d)\"%(i,key, len(topic2albums[key]), len(topic2stories[key])))\n",
    "\n",
    "\n",
    "sis.Topics = Topics = {topic : {'story_ids' : topic2stories[topic], 'album_ids' : topic2albums[topic]} for topic in topic2stories}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408\n"
     ]
    }
   ],
   "source": [
    "def Most_Common(lst):\n",
    "   \n",
    "    return \n",
    "\n",
    "def convert_one_hot(labels_list):\n",
    "    one_hot = [0] * 5\n",
    "#     for order in labels_list:\n",
    "#         one_hot[order] = 1\n",
    "    data = Counter(labels_list)\n",
    "    one_hot[data.most_common(1)[0][0]] = 1\n",
    "    return one_hot\n",
    "\n",
    "img2labels = {}\n",
    "for im_name in img2features:\n",
    "    img_id = im_name.split('.')[0]\n",
    "    img2labels[img_id] = []\n",
    "    \n",
    "for story in sis.Stories.values():\n",
    "    for order, img_id in enumerate(story['img_ids']):\n",
    "        img2labels[img_id].append(order)\n",
    "    \n",
    "\n",
    "# r_img_id = random.choice(list(img2labels.keys()))\n",
    "# print(r_img_id)\n",
    "# print(img2labels[r_img_id])\n",
    "\n",
    "\n",
    "img2labels = {img_id : convert_one_hot(img2labels[img_id]) for img_id in img2labels if img2labels[img_id]}\n",
    "\n",
    "\n",
    "\n",
    "relevant_topics = [\"4th_of_july\", \"bike_race\", \"award_ceremony\", \"birthday\"]\n",
    "\n",
    "relevant_img_ids = set([])\n",
    "\n",
    "for topic in relevant_topics:\n",
    "    for story_id in sis.Topics[topic][\"story_ids\"]:\n",
    "        relevant_img_ids.update(sis.Stories[story_id][\"img_ids\"])\n",
    "\n",
    "        \n",
    "img2labels = {img_id : img2labels[img_id] for img_id in img2labels if img_id in relevant_img_ids}\n",
    "        \n",
    "        \n",
    "print(len(relevant_img_ids))\n",
    "# for img_id in img2labels:\n",
    "#     print(img2labels[img_id])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test split: 80% / 19 %\n",
      "Train size: 1126\n",
      "Test size: 282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19999999999999996"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.zeros((len(img2labels), 4096))\n",
    "Y = np.zeros((len(img2labels), 5))\n",
    "\n",
    "for i, img_id in enumerate(img2labels):\n",
    "\n",
    "    X[i,:] = img2features[img_id + '.jpg']\n",
    "    Y[i,:] = img2labels[img_id]\n",
    "    \n",
    "train_per = 0.8\n",
    "train_features = X[:int(0.8*X.shape[0]), :]\n",
    "train_labels = Y[:int(0.8*X.shape[0]), :]\n",
    "\n",
    "test_features = X[int(0.8*X.shape[0]):, :]\n",
    "test_labels = Y[int(0.8*X.shape[0]):, :]\n",
    "\n",
    "print(\"Train/test split: %d%% / %d %%\" % (train_per * 100,(1-train_per) * 100))\n",
    "print(\"Train size: %d\" %(len(train_features)))\n",
    "print(\"Test size: %d\" %(len(test_features)))\n",
    "\n",
    "(1-train_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 5164.449751420\n",
      "Epoch: 0002 cost= 2995.343661222\n",
      "Epoch: 0003 cost= 2053.805941495\n",
      "Epoch: 0004 cost= 1719.566827947\n",
      "Epoch: 0005 cost= 1471.346768466\n",
      "Epoch: 0006 cost= 1286.047762784\n",
      "Epoch: 0007 cost= 1135.051169656\n",
      "Epoch: 0008 cost= 1007.268582431\n",
      "Epoch: 0009 cost= 898.768610174\n",
      "Epoch: 0010 cost= 803.263982599\n",
      "Epoch: 0011 cost= 718.648210005\n",
      "Epoch: 0012 cost= 642.618252841\n",
      "Epoch: 0013 cost= 576.029196999\n",
      "Epoch: 0014 cost= 515.952448065\n",
      "Epoch: 0015 cost= 463.880099210\n",
      "Epoch: 0016 cost= 417.364554665\n",
      "Epoch: 0017 cost= 375.761180531\n",
      "Epoch: 0018 cost= 337.725705233\n",
      "Epoch: 0019 cost= 304.189591841\n",
      "Epoch: 0020 cost= 272.283698342\n",
      "Epoch: 0021 cost= 245.483756325\n",
      "Epoch: 0022 cost= 220.010155418\n",
      "Epoch: 0023 cost= 196.490743464\n",
      "Epoch: 0024 cost= 176.804343484\n",
      "Epoch: 0025 cost= 159.138189836\n",
      "Epoch: 0026 cost= 141.981986306\n",
      "Epoch: 0027 cost= 126.853925532\n",
      "Epoch: 0028 cost= 112.411239624\n",
      "Epoch: 0029 cost= 100.238238248\n",
      "Epoch: 0030 cost= 88.883920496\n",
      "Epoch: 0031 cost= 80.210989172\n",
      "Epoch: 0032 cost= 72.553232366\n",
      "Epoch: 0033 cost= 65.071800232\n",
      "Epoch: 0034 cost= 56.860088348\n",
      "Epoch: 0035 cost= 50.570885225\n",
      "Epoch: 0036 cost= 43.542633057\n",
      "Epoch: 0037 cost= 37.749921799\n",
      "Epoch: 0038 cost= 33.081722953\n",
      "Epoch: 0039 cost= 29.312211123\n",
      "Epoch: 0040 cost= 25.719953797\n",
      "Epoch: 0041 cost= 22.745873278\n",
      "Epoch: 0042 cost= 19.880172209\n",
      "Epoch: 0043 cost= 17.327914932\n",
      "Epoch: 0044 cost= 15.103219206\n",
      "Epoch: 0045 cost= 13.070330230\n",
      "Epoch: 0046 cost= 11.130327528\n",
      "Epoch: 0047 cost= 9.528353301\n",
      "Epoch: 0048 cost= 7.638741407\n",
      "Epoch: 0049 cost= 6.593403925\n",
      "Epoch: 0050 cost= 5.241792516\n",
      "Optimization Finished!\n",
      "Accuracy: 0.184397\n"
     ]
    }
   ],
   "source": [
    "def get_batch(X, Y, current_batch, batch_size):\n",
    "    batch_x = X[i*batch_size : (i+1)*batch_size, :]\n",
    "    batch_y = Y[i*batch_size : (i+1)*batch_size, :]\n",
    "    return batch_x, batch_y\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 50\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 100 # 1st layer number of features\n",
    "n_hidden_2 = 100 # 2nd layer number of features\n",
    "n_input = 4096 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 5 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(train_features.shape[0]/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = get_batch(train_features, train_labels, i, batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: test_features, y: test_labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'album_id': '72157623139776636',\n",
       " 'id': '223009',\n",
       " 'img_id': '4250204464',\n",
       " 'length': 8,\n",
       " 'order': 4,\n",
       " 'original_text': 'I myself prefer to use my feet.',\n",
       " 'setting': 'first-2-pick-and-tell',\n",
       " 'story_id': '44601',\n",
       " 'text': 'i myself prefer to use my feet .',\n",
       " 'tier': 'story-in-sequence',\n",
       " 'worker_id': 'AS2MDFCRUS236TU'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sis.Sents['223009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
